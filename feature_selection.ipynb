{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use forward selection using AUC criterion on logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import random\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_out.csv')\n",
    "\n",
    "read = open('train/train_na.pkl', 'rb')\n",
    "train_na = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "train.index = train.msno\n",
    "avg = np.mean(train.loc[train_na, 'is_churn'])\n",
    "train = train[~train_na]\n",
    "train = train.sample(n = 10000)\n",
    "\n",
    "\n",
    "train_X = train.drop(['msno', 'is_churn', 'concated'], axis = 1)\n",
    "train_y = train.is_churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how logistic regression does using all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Guess score:              0.936400\n",
      "Logistic Regression score:     0.082800\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(train_X, train_y)\n",
    "score = log.score(train_X, train_y)\n",
    "print('Best Guess score:              %f' % (1 - np.mean(train_y)))\n",
    "print('Logistic Regression score:     %f' % score)"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "      <th>201501</th>\n",
       "      <th>201502</th>\n",
       "      <th>201503</th>\n",
       "      <th>201504</th>\n",
       "      <th>201505</th>\n",
       "      <th>201506</th>\n",
       "      <th>201507</th>\n",
       "      <th>201508</th>\n",
       "      <th>...</th>\n",
       "      <th>city_999.0</th>\n",
       "      <th>gender_NA</th>\n",
       "      <th>gender_female</th>\n",
       "      <th>gender_male</th>\n",
       "      <th>registered_via_3.0</th>\n",
       "      <th>registered_via_4.0</th>\n",
       "      <th>registered_via_7.0</th>\n",
       "      <th>registered_via_9.0</th>\n",
       "      <th>registered_via_13.0</th>\n",
       "      <th>registered_via_999.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>msno</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=</th>\n",
       "      <td>aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=</th>\n",
       "      <td>9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=</th>\n",
       "      <td>O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=</th>\n",
       "      <td>s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=</th>\n",
       "      <td>vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                      msno  \\\n",
       "msno                                                                                         \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=  aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=  9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=  O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=  s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=  vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=   \n",
       "\n",
       "                                              is_churn  201501  201502  \\\n",
       "msno                                                                     \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=         0       1       1   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=         1      -1      -1   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=         0      -1      -1   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=         0       1       1   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=         0       1       1   \n",
       "\n",
       "                                              201503  201504  201505  201506  \\\n",
       "msno                                                                           \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=       1       1       1       1   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=      -1      -1      -1      -1   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=      -1      -1      -1      -1   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=       1       1       1      -1   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=       1       1      -1       1   \n",
       "\n",
       "                                              201507  201508  \\\n",
       "msno                                                           \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=       1       1   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=      -1      -1   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=      -1      -1   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=       1       1   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=       1       1   \n",
       "\n",
       "                                                      ...           \\\n",
       "msno                                                  ...            \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=          ...            \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=          ...            \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=          ...            \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=          ...            \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=          ...            \n",
       "\n",
       "                                              city_999.0  gender_NA  \\\n",
       "msno                                                                  \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=         0.0        0.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=         0.0        1.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=         0.0        1.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=         0.0        0.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=         0.0        0.0   \n",
       "\n",
       "                                              gender_female  gender_male  \\\n",
       "msno                                                                       \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=            0.0          1.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=            0.0          0.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=            0.0          0.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=            0.0          1.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=            1.0          0.0   \n",
       "\n",
       "                                              registered_via_3.0  \\\n",
       "msno                                                               \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                 0.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                 0.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                 0.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                 0.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                 0.0   \n",
       "\n",
       "                                              registered_via_4.0  \\\n",
       "msno                                                               \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                 0.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                 0.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                 0.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                 0.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                 0.0   \n",
       "\n",
       "                                              registered_via_7.0  \\\n",
       "msno                                                               \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                 0.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                 1.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                 1.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                 0.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                 1.0   \n",
       "\n",
       "                                              registered_via_9.0  \\\n",
       "msno                                                               \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                 1.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                 0.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                 0.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                 1.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                 0.0   \n",
       "\n",
       "                                              registered_via_13.0  \\\n",
       "msno                                                                \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                  0.0   \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                  0.0   \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                  0.0   \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                  0.0   \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                  0.0   \n",
       "\n",
       "                                              registered_via_999.0  \n",
       "msno                                                                \n",
       "aQnI+Zj9bafttiIOo1OVtoT9+X4oiZGz/pYGnHcwE04=                   0.0  \n",
       "9WAJDanxSDNr4SMZQ3vf6CWg/1iO8USmrNcJJwA1StI=                   0.0  \n",
       "O3GJ8ZlKte0pf3PlgPkmaWUQoK4odZ7zSJX44ziHy/s=                   0.0  \n",
       "s84e4DJlreeZN01wV85ugDmK0ZeiT78phzRsl63LEio=                   0.0  \n",
       "vXPuGap0iMmzI1/lmOtLTcyWXwNfMOHzodCXmJmH/T0=                   0.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
>>>>>>> origin/master
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93% is pretty bad, since that is just the mean of what we are predicting. Thus we must do forward selection to identify relevant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Variable Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea of forward variable selection is to continually add more variables to our model and seeing which variable creates the most improvements. We will continue iterating only if the model is improving. Otherwise, we will stop in order to avoid taking in noisy and irrelevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "best feature: expiration_date\n",
      "AUC:          0.715355\n",
      "Score:        0.963700\n",
      "Log Loss:     0.185571\n",
      "-----------------------\n",
      "Iteration 2\n",
      "best feature: 201702\n",
      "AUC:          0.763703\n",
      "Score:        0.962300\n",
      "Log Loss:     0.126739\n",
      "-----------------------\n",
      "Iteration 3\n",
      "best feature: is_auto_renew\n",
      "AUC:          0.798722\n",
      "Score:        0.967500\n",
      "Log Loss:     0.099077\n",
      "-----------------------\n",
      "Iteration 4\n",
      "best feature: 201506\n",
      "AUC:          0.815362\n",
      "Score:        0.967100\n",
      "Log Loss:     0.097420\n",
      "-----------------------\n",
      "Iteration 5\n",
      "best feature: membership_expire_date\n",
      "AUC:          0.825261\n",
      "Score:        0.967800\n",
      "Log Loss:     0.091949\n",
      "-----------------------\n",
      "Iteration 6\n",
      "best feature: payment_plan_days\n",
      "AUC:          0.830231\n",
      "Score:        0.967500\n",
      "Log Loss:     0.090817\n",
      "-----------------------\n",
      "Iteration 7\n",
      "best feature: 201607\n",
      "AUC:          0.836947\n",
      "Score:        0.969100\n",
      "Log Loss:     0.088787\n",
      "-----------------------\n",
      "Iteration 8\n",
      "best feature: 201606\n",
      "AUC:          0.839985\n",
      "Score:        0.969300\n",
      "Log Loss:     0.088479\n",
      "-----------------------\n",
      "Iteration 9\n",
      "Logfit is not improving...\n"
     ]
    }
   ],
   "source": [
    "isImproving = True\n",
    "features = train_X.columns\n",
    "ranked_features = []\n",
    "score = []\n",
    "logloss = []\n",
    "AUC = [0]\n",
    "i = 0\n",
    "while isImproving:\n",
    "    top_AUC = AUC[i]\n",
    "    print('Iteration %s' % str(i+1))\n",
    "    for var in train_X.columns.difference(ranked_features):\n",
    "        log = LogisticRegression()\n",
    "        log.fit(train_X[[var] + ranked_features], train_y)\n",
    "        pred = log.predict(train_X[[var] + ranked_features])\n",
    "        prob = log.predict_proba(train_X[[var] + ranked_features])\n",
    "        curr_AUC = roc_auc_score(train_y, pred)\n",
    "        if curr_AUC > top_AUC:\n",
    "            best_feature = var\n",
    "            top_AUC = curr_AUC\n",
    "            best_score= np.mean(pred == train_y)\n",
    "            top_log_loss = log_loss(train_y, prob)\n",
    "    if(AUC[i] >= top_AUC):\n",
    "        print('Logfit is not improving...')\n",
    "        isImproving = False\n",
    "        break\n",
    "    else:\n",
    "        print('best feature: %s' % best_feature)\n",
    "        print('AUC:          %f' % top_AUC)\n",
    "        print('Score:        %f' % best_score)\n",
    "        print('Log Loss:     %f' % top_log_loss)\n",
    "        print('-----------------------')\n",
    "        AUC.append(top_AUC)\n",
    "        ranked_features.append(best_feature)\n",
    "        score.append(best_score)\n",
    "        logloss.append(top_log_loss)\n",
    "    i += 1"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best features"
=======
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranked_features = ['expiration_date',\n",
    "                  'membership_expire_date',\n",
    "                  'registered_via_7.0',\n",
    "                  'is_auto_renew',\n",
    "                  'is_cancel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Variable Selection with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find the best features with cross validation fold (n_fold = 5). This will give a better idea ofwhat our actual score will be in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fold = 3\n",
    "cv = StratifiedKFold(n_splits = n_fold, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train_X.reset_index().drop(['msno'], axis = 1)\n",
    "train_y = train_y.reset_index().drop(['msno'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0b009f580341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mcurr_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi_val\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mlog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    320\u001b[0m                                                              n_samples))\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[0mtest_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtest_fold_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_cls_splits\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mper_cls_cvs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_cls_splits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m                 \u001b[0mcls_test_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_folds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m                 \u001b[1;31m# the test split can be too big because we used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                 \u001b[1;31m# KFold(...).split(X[:max(c, n_splits)]) when data is not 100%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "isImproving = True\n",
    "features = train_X.columns\n",
    "ranked_features2 = []\n",
    "score = []\n",
    "curr_score = []\n",
    "logloss = []\n",
    "curr_logloss = []\n",
    "AUC = [[0]]\n",
    "curr_cv_AUC = []\n",
    "i = 0\n",
    "while isImproving:\n",
    "    top_AUC = np.mean(AUC[i])\n",
    "    print('Iteration %s' % str(i+1))\n",
    "    for var in train_X.columns.difference(ranked_features2):\n",
    "        ### Add CV\n",
    "        \n",
    "        curr_cv_AUC = []\n",
    "        curr_logloss = []\n",
    "        curr_score = []\n",
    "        \n",
    "        for i_trn, i_val in cv.split(train_X, train_y):\n",
    "            \n",
    "            log = LogisticRegression()\n",
    "            log.fit(train_X.loc[i_trn, [var] + ranked_features2], train_y[i_trn])\n",
    "            pred = log.predict(train_X.loc[i_val, [var] + ranked_features2])\n",
    "            prob = log.predict_proba(train_X.loc[i_val, [var] + ranked_features2])\n",
    "            curr_AUC = roc_auc_score(train_y[i_val], pred)\n",
    "            curr_cv_AUC.append(curr_AUC)\n",
    "            curr_score.append(pred == train_y[i_val])\n",
    "            curr_logloss.append(log_loss(train_y[i_val], prob))\n",
    "          \n",
    "        if np.mean(curr_cv_AUC) > np.mean(top_AUC):\n",
    "            best_feature = var\n",
    "            top_AUC = curr_cv_AUC\n",
    "            best_score= curr_score\n",
    "            top_log_loss = curr_logloss\n",
    "\n",
    "    if(np.mean(AUC[i]) >= np.mean(top_AUC)):\n",
    "        print('Logfit is not improving...')\n",
    "        isImproving = False\n",
    "        break\n",
    "    else:\n",
    "        print('best feature: %s' % best_feature)\n",
    "        print('AUC:          %f' % np.mean(top_AUC))\n",
    "        print('Score:        %f' % np.mean(best_score))\n",
    "        print('Log Loss:     %f' % np.mean(top_log_loss))\n",
    "        print('-----------------------')\n",
    "        score.append(curr_score)\n",
    "        logloss.append(curr_logloss)\n",
    "        AUC.append(curr_cv_AUC)\n",
    "        AUC.append(top_AUC)\n",
    "        ranked_features2.append(best_feature)\n",
    "        score.append(best_score)\n",
    "        logloss.append(top_log_loss)\n",
    "    i += 1"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.22852491985673834, 0.22771551762172304, 0.22826281756063532],\n",
       " [0.19168042715323549, 0.19166939403941957, 0.19118863098225081],\n",
       " [0.18128228601947433, 0.18068370876893211, 0.18071214246597558],\n",
       " [0.14575567569476386, 0.14517778847512317, 0.14490048127113253],\n",
       " [0.14165583797073164, 0.14080240696779375, 0.14086321786718495],\n",
       " [0.13762068423989871, 0.13649567387260006, 0.13640331458236057],\n",
       " [0.13596901720417562, 0.13467281080735002, 0.13479734456770029],\n",
       " [0.12979934839749135, 0.1289415959384472, 0.1290855058112341],\n",
       " [0.12818631881663184, 0.12716833201299571, 0.12756544221999314],\n",
       " [0.12818631881663184, 0.12716833201299571, 0.12756544221999314]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
>>>>>>> origin/master
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss of Logistic Regression:         0.088479\n",
      "Accuracy of Logistic Regression:         0.991500\n",
      "Logistic Regression Probs Saved ~~~~\n",
      "Best features saved!\n"
     ]
    }
   ],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(train_X[ranked_features], train_y)\n",
    "prob = log.predict_proba(train_X[ranked_features])\n",
    "predict = log.predict(train_X[ranked_features])\n",
    "print(\"Log Loss of Logistic Regression:         %f\" % log_loss(train_y, prob))\n",
    "print('Accuracy of Logistic Regression:         %f' % (1 - np.mean(train_y - predict)))\n",
    "output = open('models/log_probs.pkl', 'wb')\n",
    "pickle.dump(prob, output, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "output.close\n",
    "print('Logistic Regression Probs Saved ~~~~')\n",
    "output = open('train/best_features.pkl', 'wb')\n",
    "pickle.dump(ranked_features, output, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "output.close()\n",
    "print('Best features saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
