{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kkbox features + EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The purpose of this notebook is to summarise all data files into useful chunks of data, and merge them to the train and test csv. Our output is train_out.csv and test_out.csv. Visualization of the features will be made at the end to see possible trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "import time\n",
    "\n",
    "import os\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('data/transactions.csv')\n",
    "members = pd.read_csv('data/members.csv')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/sample_submission_zero.csv')\n",
    "user_logs = pd.read_csv('data/user_logs_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what our datafiles look like. We will investigate each file individually, and then merge them all later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transactions Shape:               (21547746, 9)\n",
      "Members Shape:                    (5116194, 7)\n",
      "Train Shape:                      (992931, 2)\n",
      "Test Shape:                       (970960, 2)\n",
      "User Logs Output:                 (5234111, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Transactions Shape:               %s' % str(transactions.shape))\n",
    "print('Members Shape:                    %s' % str(members.shape))\n",
    "print('Train Shape:                      %s' % str(train.shape))\n",
    "print('Test Shape:                       %s' % str(test.shape))\n",
    "print('User Logs Output:                 %s' % str(user_logs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 992,931 in our training dataset and 970,960 in our test. Not too bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=         1\n",
       "1  QA7uiXy8vIbUSPOkCf9RwQ3FsT8jVq2OxDr8zqa7bRQ=         1\n",
       "2  fGwBva6hikQmTJzrbz/2Ezjm5Cth5jZUNvXigKK2AFA=         1\n",
       "3  mT5V8rEpa+8wuqi6x0DoVd3H5icMKkE9Prt49UlmK+4=         1\n",
       "4  XaPhtGLk/5UvvOYHcONTwsnH97P4eGECeq+BARGItRw=         1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  ugx0CjOMzazClkFzU2xasmDZaoIqOUAZPsH1q0teWCg=         0\n",
       "1  f/NmvEzHfhINFEYZTR05prUdr+E+3+oewvweYz9cCQE=         0\n",
       "2  zLo9f73nGGT1p21ltZC3ChiRnAVvgibMyazbCxvWPcg=         0\n",
       "3  8iF/+8HY8lJKFrTc7iR9ZYGCG2Ecrogbc2Vy5YhsfhQ=         0\n",
       "4  K6fja4+jmoZ5xG6BypqX80Uw/XKpMgrEMdG2edFOxnA=         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both train and test datafiles have msno (user id) and is_churn. `Test['is_churn']` is what we would want to predict. Let's see what is the percent of people churning in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ppl who churn:            0.063923\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of ppl who churn:            %f' % np.mean(train.is_churn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the competition scoring uses logloss, we want to keep in mind that 94% accuracy is our \"median Best Guess model.\" We want our models to perform significantly higher than this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One basic feature that we can add is mean statistics of the transaction data (which we will name transaction_sum.csv). Another thing that we can do is get an idea of months that users dropped, maintained or added a subscription to kkbox (which we will name recency.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Unique Users:        2363626\n"
     ]
    }
   ],
   "source": [
    "index = set(transactions['msno'])\n",
    "print('# Unique Users:        %d' % len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151031</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20160427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151121</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=                 41   \n",
       "1  AZtu6Wl0gPojrEQYB8Q3vBSmE2wnZ3hi1FbK1rQQ0A4=                 41   \n",
       "2  UkDFI97Qb6+s2LWcijVVv4rMAsORbVDT2wNXF0aVbns=                 41   \n",
       "3  M1C56ijxozNaGD0t2h68PnH2xtx5iO5iR2MVYQB6nBI=                 39   \n",
       "4  yvj6zyBUaqdbUQSrKsrZ+xNDVM62knauSZJzakS9OW4=                 39   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                 149              1   \n",
       "2                 30              129                 129              1   \n",
       "3                 30              149                 149              1   \n",
       "4                 30              149                 149              1   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20150930                20151101          0  \n",
       "1          20150930                20151031          0  \n",
       "2          20150930                20160427          0  \n",
       "3          20150930                20151128          0  \n",
       "4          20150930                20151121          0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at one individual user's transaction history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5385571</th>\n",
       "      <td>lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150131</td>\n",
       "      <td>20150319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150228</td>\n",
       "      <td>20150419</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502405</th>\n",
       "      <td>lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=</td>\n",
       "      <td>39</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150331</td>\n",
       "      <td>20150519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9947404</th>\n",
       "      <td>lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150430</td>\n",
       "      <td>20150619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15237221</th>\n",
       "      <td>lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20150531</td>\n",
       "      <td>20150719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  msno  payment_method_id  \\\n",
       "5385571   lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=                 39   \n",
       "100       lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=                 39   \n",
       "6502405   lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=                 39   \n",
       "9947404   lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=                 39   \n",
       "15237221  lF0lx58JJRNAU7yIb8p7gQGkpHVxuZgGoBpeucDSpxo=                 39   \n",
       "\n",
       "          payment_plan_days  plan_list_price  actual_amount_paid  \\\n",
       "5385571                  31              149                 149   \n",
       "100                      31              149                 149   \n",
       "6502405                  31              149                 149   \n",
       "9947404                   0                0                 149   \n",
       "15237221                 30              149                 149   \n",
       "\n",
       "          is_auto_renew  transaction_date  membership_expire_date  is_cancel  \n",
       "5385571               1          20150131                20150319          0  \n",
       "100                   1          20150228                20150419          0  \n",
       "6502405               1          20150331                20150519          0  \n",
       "9947404               1          20150430                20150619          0  \n",
       "15237221              1          20150531                20150719          0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions[transactions['msno'] == transactions.msno[100]].sort_values('transaction_date').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic features that we can add are\n",
    "* `total_sub_days`\n",
    "* `start_sub`\n",
    "* `end_sub`\n",
    "* `num_canceled`\n",
    "* `num_transactions`\n",
    "\n",
    "We will save this information to transaction_sum.csv stored in `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_sub_days = transactions.groupby(['msno']).payment_plan_days.sum()\n",
    "start_sub = transactions.groupby(['msno']).transaction_date.min()\n",
    "end_sub = transactions.groupby(['msno']).membership_expire_date.max()\n",
    "num_canceled = transactions.groupby(['msno']).is_cancel.sum()\n",
    "num_auto_renew = transactions.groupby(['msno']).is_auto_renew.sum()\n",
    "num_transactions = transactions.groupby(['msno']).size()\n",
    "\n",
    "transaction_sum = pd.concat([total_sub_days, start_sub, \n",
    "                             end_sub, num_canceled, \n",
    "                             num_auto_renew, num_transactions], axis = 1)\n",
    "\n",
    "transaction_sum.to_csv('data/transaction_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can extract information about months that users dropped, maintained or added a subscription. Basically, the months from 01/2015 - 02/2017 will be our features. \n",
    "\n",
    "This is our code for each month:\n",
    "\n",
    "* dropped/not subscribed:      -1\n",
    "* maintained:                   0\n",
    "* added:                        1\n",
    "\n",
    "*Creating this file can take a while. Step back and drink some tea in the meantime*\n",
    "\n",
    "We will save this information to recency.csv stored in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_months = list(set([int(i/100) for i in transactions.transaction_date]))\n",
    "unique_months = sorted(unique_months)\n",
    "recency = pd.DataFrame(-1, index = list(index), columns = unique_months)\n",
    "\n",
    "past = time.time()\n",
    "\n",
    "for index, row in transactions.iterrows():\n",
    "    user = row['msno']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    if row['is_cancel'] == 0:\n",
    "        recency.loc[user, start:end] = 0\n",
    "    elif row['is_cancel'] == 1:\n",
    "        recency.loc[user, start:] = -1\n",
    "    if i % 1000000 == 0:\n",
    "        print('Iteration %d , Elapsed     %f' % (i, time.time() - past))\n",
    "    \n",
    "recency.to_csv('data/recency.csv')\n",
    "print('Completed and saved!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are done with that (finally)! Now let's move on too other datafiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "      <th>expiration_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URiXrfYPzHAlk+7+n7BOMl9G+T7g8JmrSnT/BU8GmEo=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20150525</td>\n",
       "      <td>20150526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1q0qCqK/lDMTD2kN8G9OXMtfuvLCey20OAIPOvXXGQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20161221</td>\n",
       "      <td>20161224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W6M2H2kAoN9ahfDYKo3J6tmsJRAeuFc9wl1cau5VL1Q=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20160306</td>\n",
       "      <td>20160309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1qE5+cN7CUyC+KFH6gBZzMWmM1QpIVW6A43BEm98I/w=</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>20161031</td>\n",
       "      <td>20161107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SeAnaZPI+tFdAt+r3lZt/B8PgTp7bcG/1os39u4pLxs=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170202</td>\n",
       "      <td>20170205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  URiXrfYPzHAlk+7+n7BOMl9G+T7g8JmrSnT/BU8GmEo=     1   0     NaN   \n",
       "1  U1q0qCqK/lDMTD2kN8G9OXMtfuvLCey20OAIPOvXXGQ=     1   0     NaN   \n",
       "2  W6M2H2kAoN9ahfDYKo3J6tmsJRAeuFc9wl1cau5VL1Q=     1   0     NaN   \n",
       "3  1qE5+cN7CUyC+KFH6gBZzMWmM1QpIVW6A43BEm98I/w=     5  17  female   \n",
       "4  SeAnaZPI+tFdAt+r3lZt/B8PgTp7bcG/1os39u4pLxs=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  expiration_date  \n",
       "0               9                20150525         20150526  \n",
       "1               4                20161221         20161224  \n",
       "2               4                20160306         20160309  \n",
       "3               4                20161031         20161107  \n",
       "4               4                20170202         20170205  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These seem like good features already. I won't touch them so it's all ready to join with the train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the datafiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have\n",
    "\n",
    "* transaction_sum.csv\n",
    "* recency.csv\n",
    "* members.csv\n",
    "\n",
    "... to join to the train and test datasets. Let's do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.index = train.msno\n",
    "test.index = test.msno\n",
    "members.index = members.msno\n",
    "members = members.drop(['msno'], axis = 1)\n",
    "user_logs.index = user_logs.msno\n",
    "user_logs = user_logs.drop(['msno'], axis = 1)\n",
    "recency.index = recency['Unnamed: 0']\n",
    "recency = recency.drop(['Unnamed: 0'], axis = 1)\n",
    "transaction_sum.index = transaction_sum.msno\n",
    "transaction_sum = transaction_sum.drop(['msno'], axis = 1)\n",
    "\n",
    "train = pd.concat([train, recency, members, transaction_sum, user_logs], \n",
    "                  axis = 1, join='outer', join_axes = [train.index])\n",
    "\n",
    "test = pd.concat([test, recency, members, transaction_sum, user_logs], \n",
    "                 axis = 1, join='outer', join_axes = [test.index])\n",
    "\n",
    "#Fix some column names\n",
    "train.rename(columns = {list(train)[-3]: 'num_transactions'}, inplace = True)\n",
    "test.rename(columns = {list(test)[-3]: 'num_transactions'}, inplace = True)\n",
    "print('Completed!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple ideas that we can implement to make our features better. \n",
    "\n",
    "For one, the recency data has useful information about user subscription cycles. We can use the numbers to calculate longest consecutive 1's or consecutive 0's to get an idea of longest period of monthly subscriptions or longest period of a subscription. \n",
    "\n",
    "Another thing is that since the dates are stored as integers, we can set an arbitrary pivot date and get a delta date to create a continuous date scale. Otherwise, the gap between 12/31/2015 and 01/01/2016 is significantly longer than the gap between 01/01/2016 and 01/02/2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the consecutives. I've defined some functions to help. This chunk might take awhile as well (go big data!), so sit back and relax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def len_consec_zeros(a):\n",
    "    a = np.array(list(a))   \n",
    "    rr = np.argwhere(a == '0').ravel()  \n",
    "    if not rr.size:\n",
    "        return 0\n",
    "    full = np.arange(rr[0], rr[-1]+1) \n",
    "    diff = np.setdiff1d(full, rr)\n",
    "    if not diff.size:\n",
    "        return len(full)\n",
    "    pos, difs = full[0], []\n",
    "    for el in diff:\n",
    "        difs.append(el - pos)\n",
    "        pos = el + 1\n",
    "    difs.append(full[-1]+1 - pos)\n",
    "    res = max(difs) if max(difs) != 1 else 0\n",
    "    return res\n",
    "\n",
    "def len_consec_ones(a):\n",
    "    a = np.array(list(a))   \n",
    "    rr = np.argwhere(a == '1').ravel()  \n",
    "    if not rr.size:\n",
    "        return 0\n",
    "    full = np.arange(rr[0], rr[-1]+1) \n",
    "    diff = np.setdiff1d(full, rr)\n",
    "    if not diff.size:\n",
    "        return len(full)\n",
    "    pos, difs = full[0], []\n",
    "    for el in diff:\n",
    "        difs.append(el - pos)\n",
    "        pos = el + 1\n",
    "    difs.append(full[-1]+1 - pos)\n",
    "    res = max(difs) if max(difs) != 1 else 0\n",
    "    return res\n",
    "\n",
    "train['concated'] = train.ix[:, 3:27].astype(str).apply(lambda x: ''.join(x), axis=1)\n",
    "train['consecutive_zeros'] = train.concated.apply(lambda x: len_consec_zeros(x))\n",
    "train['consecutive_ones'] = train.concated.apply(lambda x: len_consec_ones(x))\n",
    "\n",
    "test['concated'] = test.ix[:, 3:27].astype(str).apply(lambda x: ''.join(x), axis=1)\n",
    "test['consecutive_zeros'] = test.concated.apply(lambda x: len_consec_zeros(x))\n",
    "test['consecutive_ones'] = test.concated.apply(lambda x: len_consec_ones(x))\n",
    "print('Completed!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dates. This part is relatively straight forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_date(i):\n",
    "    year = int(i / 10000)\n",
    "    month = int(int(i % 10000) / 100)\n",
    "    day = int(i % 100)\n",
    "    return dt.date(year, month, day)\n",
    "\n",
    "pivot = dt.date(2017, 2, 28)\n",
    "\n",
    "train.loc[~train.registration_init_time.isnull(), 'registration_init_time'] = [(pivot - get_date(i)).days / 30 for i in train.loc[~train.registration_init_time.isnull(), 'registration_init_time']]\n",
    "train.loc[~train.expiration_date.isnull(), 'expiration_date'] = [(pivot - get_date(i)).days / 30 for i in train.loc[~train.expiration_date.isnull(), 'expiration_date']]\n",
    "train.loc[~train.transaction_date.isnull(), 'transaction_date'] = [(pivot - get_date(i)).days / 30 for i in train.loc[~train.transaction_date.isnull(), 'transaction_date']]\n",
    "train.loc[~train.membership_expire_date.isnull(), 'membership_expire_date'] = [(pivot - get_date(i)).days / 30 for i in train.loc[~train.membership_expire_date.isnull(), 'membership_expire_date']]\n",
    "\n",
    "test.loc[~test.registration_init_time.isnull(), 'registration_init_time'] = [(pivot - get_date(i)).days / 30 for i in test.loc[~test.registration_init_time.isnull(), 'registration_init_time']]\n",
    "test.loc[~test.expiration_date.isnull(), 'expiration_date'] = [(pivot - get_date(i)).days / 30 for i in test.loc[~test.expiration_date.isnull(), 'expiration_date']]\n",
    "test.loc[~test.transaction_date.isnull(), 'transaction_date'] = [(pivot - get_date(i)).days / 30 for i in test.loc[~test.transaction_date.isnull(), 'transaction_date']]\n",
    "test.loc[~test.membership_expire_date.isnull(), 'membership_expire_date'] = [(pivot - get_date(i)).days / 30 for i in test.loc[~test.membership_expire_date.isnull(), 'membership_expire_date']]\n",
    "print('Completed!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ewwww... Missing data. It's important to realize that not all users in the train or test is in transactions or members. So unfortunately, we have missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num_missing(x):\n",
    "    return sum(x.isnull())\n",
    "\n",
    "#Applying per column\n",
    "print (\"Train missing values:\")\n",
    "print (\"---------------------------------\")\n",
    "print (train.apply(num_missing, axis=0))\n",
    "print('')\n",
    "print (\"Test missing values:\")\n",
    "print (\"---------------------------------\")\n",
    "print (test.apply(num_missing, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical variables, we will fill in the missing values with NA's and 999's. Don't forget to hot-encode the categories too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.loc[train.city.isnull(), 'city'] = 999\n",
    "test.loc[test.city.isnull(), 'city'] = 999\n",
    "\n",
    "train.loc[train.gender.isnull(), 'gender'] = 'NA'\n",
    "test.loc[test.gender.isnull(), 'gender'] = 'NA'\n",
    "\n",
    "train.loc[train.registered_via.isnull(), 'registered_via'] = 999\n",
    "test.loc[test.registered_via.isnull(), 'registered_via'] = 999\n",
    "\n",
    "train = pd.get_dummies(train, columns = ['city', 'gender', 'registered_via'])\n",
    "test = pd.get_dummies(test, columns = ['city', 'gender', 'registered_via'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous, we will fill in the missing values with the average of the combined dataset. We will store train_na and test_na indexes in case we decide to use them in the training/predicting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([train, test])\n",
    "\n",
    "def reject_outliers(data, m=2):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "var = ['registration_init_time',\n",
    "      'expiration_date',\n",
    "      'payment_plan_days',\n",
    "      'transaction_date',\\n\",\n",
    "      'membership_expire_date',\n",
    "      'is_cancel',\n",
    "      'is_auto_renew',\n",
    "      'num_transactions',\n",
    "      'num_unq',\n",
    "      'total_secs']\n",
    "\n",
    "avg = np.mean(reject_outliers(combined[var]))\n",
    "train_na = train[var].isnull().any(axis = 1)\n",
    "test_na = test[var].isnull().any(axis = 1)\n",
    "\n",
    "for i in np.arange(len(var)):\n",
    "    #train.loc[mask, var[i]] = avg[i] I'm trying not to do it with the train\n",
    "    test.loc[test_na, var[i]] = avg[i]\n",
    "    \n",
    "test.ix[test['201501'].isnull(), 3:27] = 0\n",
    "    \n",
    "output = open('train/train_na.pkl', 'wb')\n",
    "pickle.dump(train_na, output, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "output.close()\n",
    "\n",
    "output = open('train/test_na.pkl', 'wb')\n",
    "pickle.dump(test_na, output, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "output.close()\n",
    "print('Completed!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to save all your hardwork!\n",
    "\n",
    "train_out = pd.read_csv('data/train_out.csv')\n",
    "test_out = pd.read_csv('data/test_out.csv')\n",
    "print('Completed and Saved!!! ヽ(^◇^*)/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "work in progress..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
