{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import os.path as path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = path.join(path.dirname(os.getcwd()), 'models')\n",
    "data_dir = path.join(path.dirname(os.getcwd()), 'data', 'train_out.csv')\n",
    "\n",
    "read = open('best_features.pkl', 'rb')\n",
    "ranked_features = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "read = open('train_na.pkl', 'rb')\n",
    "train_na = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "read = open('test_na.pkl', 'rb')\n",
    "test_na = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "ranked_features = ['expiration_date',\n",
    "                   '201702',\n",
    "                  'membership_expire_date',\n",
    "                  'consecutive_ones',\n",
    "                  'consecutive_zeros',\n",
    "                  'registered_via_7.0',\n",
    "                  'is_cancel',\n",
    "                  'is_auto_renew']\n",
    "\n",
    "train_out = pd.read_csv(data_dir)\n",
    "train_out.index = train_out.msno\n",
    "avg = np.mean(train_out.loc[train_na, 'is_churn'])\n",
    "train_out = train_out[~train_na]\n",
    "train_X = train_out.drop(['msno', 'is_churn'], axis = 1)\n",
    "train_X = train_X[ranked_features]\n",
    "train_y = train_out.is_churn\n",
    "\n",
    "data_dir = path.join(path.dirname(os.getcwd()), 'data', 'test_out.csv')\n",
    "test_out = pd.read_csv(data_dir)\n",
    "test_out.index = test_out.msno\n",
    "test_X = test_out.drop(['msno', 'is_churn'], axis = 1)\n",
    "test_X = test_X[ranked_features]\n",
    "test_y = test_out.is_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['expiration_date',\n",
       " '201702',\n",
       " 'membership_expire_date',\n",
       " 'consecutive_ones',\n",
       " 'consecutive_zeros',\n",
       " 'registered_via_7.0',\n",
       " 'is_cancel',\n",
       " 'is_auto_renew']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = LogisticRegression()\n",
    "log.fit(train_X, train_y)\n",
    "prob = log.predict_proba(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression log loss:           0.091552\n",
      "Logistic Regression probs saved!\n",
      "Logistic Regression Classifier Saved!\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression log loss:           %f' % log_loss(train_y, prob))\n",
    "save_dir = path.join(path.dirname(os.getcwd()), 'models', 'gbc_probs.pkl')\n",
    "output = open(save_dir, 'wb')\n",
    "pickle.dump(prob, output, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "output.close()\n",
    "print('Logistic Regression probs saved!')\n",
    "save_dir = path.join(path.dirname(os.getcwd()), 'models', 'log.pkl')\n",
    "output = open(save_dir, 'wb')\n",
    "pickle.dump(log, output, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "output.close()\n",
    "print('Logistic Regression Classifier Saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Log Predictions to:      C:\\Users\\Michael\\Documents\\python\\kkbox\\submissions\\gbc_submission.csv\n"
     ]
    }
   ],
   "source": [
    "test_X = test_X.loc[~test_na]\n",
    "\n",
    "pred = log.predict_proba(test_X)\n",
    "pred = pred[:,1]\n",
    "index = test_out.loc[~test_na, 'msno']\n",
    "d = {\n",
    "    'msno': index,\n",
    "    'is_churn': pred\n",
    "}\n",
    "\n",
    "log_submission = pd.DataFrame(d)\n",
    "\n",
    "log_submission = log_submission.append(pd.DataFrame({'msno': test_na[test_na == True].index, \n",
    "                                    'is_churn': [avg] * len(test_na[test_na == True].index)}))\n",
    "\n",
    "save_dir = path.join(path.dirname(os.getcwd()), 'submissions')\n",
    "log_submission.to_csv(path.join(save_dir, 'log_submission.csv'), index = False)\n",
    "print('Saved Log Predictions to:      %s' % path.join(save_dir, 'gbc_submission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05956939778864728"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(log_submission.is_churn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
