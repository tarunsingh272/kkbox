{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gc; gc.enable()\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import os.path as path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = open('train_na.pkl', 'rb')\n",
    "train_na = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "read = open('test_na.pkl', 'rb')\n",
    "test_na = pickle.load(read)\n",
    "read.close()\n",
    "\n",
    "data_dir = path.join(path.dirname(os.getcwd()), 'data', 'train_out.csv')\n",
    "train_out = pd.read_csv(data_dir)\n",
    "train_out.index = train_out.msno\n",
    "train_out = train_out[~train_na]\n",
    "train_X = train_out.drop(['msno', 'concated', \n",
    "                          'is_churn'], axis = 1)\n",
    "train_y = train_out.is_churn\n",
    "\n",
    "data_dir = path.join(path.dirname(os.getcwd()), 'data', 'test_out.csv')\n",
    "test_out = pd.read_csv(data_dir)\n",
    "test_X = test_out.drop(['msno', 'concated', \n",
    "                          'is_churn'], axis = 1)\n",
    "test_y = test_out.is_churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-log_loss:0.674897\tvalid-log_loss:0.67489\n",
      "Multiple eval metrics have been passed: 'valid-log_loss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-log_loss hasn't improved in 50 rounds.\n",
      "[50]\ttrain-log_loss:0.237721\tvalid-log_loss:0.237788\n",
      "[100]\ttrain-log_loss:0.120564\tvalid-log_loss:0.120955\n"
     ]
    }
   ],
   "source": [
    "def xgb_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'log_loss', log_loss(labels, preds)\n",
    "\n",
    "fold = 1\n",
    "for i in range(fold):\n",
    "    params = {\n",
    "        'eta': 0.02, #use 0.002\n",
    "        'max_depth': 7,\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'seed': i,\n",
    "        'silent': True\n",
    "    }\n",
    "    x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=0.3, random_state=i)\n",
    "    watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "    model = xgb.train(params, xgb.DMatrix(x1, y1), 150,  watchlist, feval=xgb_score, maximize=False, verbose_eval=50, early_stopping_rounds=50) #use 1500\n",
    "    if i != 0:\n",
    "        pred += model.predict(xgb.DMatrix(test_X), ntree_limit=model.best_ntree_limit)\n",
    "    else:\n",
    "        pred = model.predict(xgb.DMatrix(test_X), ntree_limit=model.best_ntree_limit)\n",
    "pred /= fold\n",
    "pred = pred.clip(0.0000001, 0.999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.063030228"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved XGB Predictions to:      C:\\Users\\Michael\\Documents\\python\\kkbox\\submissions\\xgb_submission.csv\n"
     ]
    }
   ],
   "source": [
    "index = test_out.msno\n",
    "\n",
    "d = {\n",
    "    'msno': index,\n",
    "    'is_churn': pred\n",
    "    }\n",
    "\n",
    "xgb_submission = pd.DataFrame(d)\n",
    "save_dir = path.join(path.dirname(os.getcwd()), 'submissions')\n",
    "xgb_submission.to_csv(path.join(save_dir, 'xgb_submission.csv'), index = False)\n",
    "print('Saved XGB Predictions to:      %s' % path.join(save_dir, 'xgb_submission.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
